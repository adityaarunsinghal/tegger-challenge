{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import regex as re\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"/Users/aditya/Documents/GitHub/tegger-challenge/bbc/\"\n",
    "contents = []\n",
    "themes = []\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if(re.match(r\"\\d*\\.txt\", file)):\n",
    "            f = open(os.path.join(root, file), 'r', encoding='latin1')\n",
    "            # string = f.read()\n",
    "            contents.append(f.read())\n",
    "            themes.append(root[len(path):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['all'] = contents\n",
    "data['theme'] = themes\n",
    "data['title'] = data['all'].apply(lambda x: x[:x.find('\\n')])\n",
    "data['contents'] = data['all'].apply(lambda x: x[x.find('\\n')+2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 all          theme  \\\n",
       "0  Musicians to tackle US red tape\\n\\nMusicians' ...  entertainment   \n",
       "1  U2's desire to be number one\\n\\nU2, who have w...  entertainment   \n",
       "2  Rocker Doherty in on-stage fight\\n\\nRock singe...  entertainment   \n",
       "3  Snicket tops US box office chart\\n\\nThe film a...  entertainment   \n",
       "4  Ocean's Twelve raids box office\\n\\nOcean's Twe...  entertainment   \n",
       "\n",
       "                              title  \\\n",
       "0   Musicians to tackle US red tape   \n",
       "1      U2's desire to be number one   \n",
       "2  Rocker Doherty in on-stage fight   \n",
       "3  Snicket tops US box office chart   \n",
       "4   Ocean's Twelve raids box office   \n",
       "\n",
       "                                            contents  \n",
       "0  Musicians' groups are to tackle US visa regula...  \n",
       "1  U2, who have won three prestigious Grammy Awar...  \n",
       "2  Rock singer Pete Doherty has been involved in ...  \n",
       "3  The film adaptation of Lemony Snicket novels h...  \n",
       "4  Ocean's Twelve, the crime caper sequel starrin...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>all</th>\n      <th>theme</th>\n      <th>title</th>\n      <th>contents</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Musicians to tackle US red tape\\n\\nMusicians' ...</td>\n      <td>entertainment</td>\n      <td>Musicians to tackle US red tape</td>\n      <td>Musicians' groups are to tackle US visa regula...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U2's desire to be number one\\n\\nU2, who have w...</td>\n      <td>entertainment</td>\n      <td>U2's desire to be number one</td>\n      <td>U2, who have won three prestigious Grammy Awar...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Rocker Doherty in on-stage fight\\n\\nRock singe...</td>\n      <td>entertainment</td>\n      <td>Rocker Doherty in on-stage fight</td>\n      <td>Rock singer Pete Doherty has been involved in ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Snicket tops US box office chart\\n\\nThe film a...</td>\n      <td>entertainment</td>\n      <td>Snicket tops US box office chart</td>\n      <td>The film adaptation of Lemony Snicket novels h...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ocean's Twelve raids box office\\n\\nOcean's Twe...</td>\n      <td>entertainment</td>\n      <td>Ocean's Twelve raids box office</td>\n      <td>Ocean's Twelve, the crime caper sequel starrin...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['argentina',\n",
       " 'australia',\n",
       " 'brazil',\n",
       " 'canada',\n",
       " 'china',\n",
       " 'france',\n",
       " 'germany',\n",
       " 'india',\n",
       " 'indonesia',\n",
       " 'italy',\n",
       " 'japan',\n",
       " 'republic of korea',\n",
       " 'korea',\n",
       " 'mexico',\n",
       " 'russia',\n",
       " 'saudi arabia',\n",
       " 'arabia',\n",
       " 'south africa',\n",
       " 'africa',\n",
       " 'turkey',\n",
       " 'united kingdom',\n",
       " 'uk',\n",
       " 'united states',\n",
       " 'america',\n",
       " 'usa',\n",
       " 'european union',\n",
       " 'eu',\n",
       " 'europe']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "g20 = \"Argentina, Australia, Brazil, Canada, China, France, Germany, India, Indonesia, Italy, Japan, Republic of Korea, Korea, Mexico, Russia, Saudi Arabia, Arabia, South Africa, Africa, Turkey, United Kingdom, UK, United States, America, USA, European Union, EU, Europe\".lower()\n",
    "g20 = g20.split(\", \")\n",
    "g20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def preprocess_non(non_word):\n",
    "    non_word = non_word.lower()\n",
    "    non_word = \"\".join([char for char in non_word if char not in string.punctuation])\n",
    "    if (non_word in stop_words or non_word == \"\"):\n",
    "        return(\"\")\n",
    "    non_word = lemmatizer.lemmatize(non_word)\n",
    "    return(non_word)\n",
    "\n",
    "def preprocess_g20(g_word):\n",
    "    g_word = g_word.upper()\n",
    "    g_word = \"*\"+g_word\n",
    "    return(g_word)\n",
    "\n",
    "def preprocess(entry):\n",
    "    entry = entry.replace(\"US\", \"USA\")\n",
    "    entry = word_tokenize(entry)\n",
    "    entry = [preprocess_g20(word) if word.lower() in g20 else preprocess_non(word) for word in entry]\n",
    "    entry = \" \".join(entry)\n",
    "    entry = re.sub(' +', ' ', entry)\n",
    "    return(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['all'] = data['all'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                    all          theme  \\\n",
       "0     musician tackle *USA red tape musician group t...  entertainment   \n",
       "1     u2 desire number one u2 three prestigious gram...  entertainment   \n",
       "2     rocker doherty onstage fight rock singer pete ...  entertainment   \n",
       "3     snicket top *USA box office chart film adaptat...  entertainment   \n",
       "4     ocean twelve raid box office ocean twelve crim...  entertainment   \n",
       "...                                                 ...            ...   \n",
       "2220  warning window word file writing microsoft wor...           tech   \n",
       "2221  fast lift rise record book two highspeed lift ...           tech   \n",
       "2222  nintendo add medium playing d nintendo releasi...           tech   \n",
       "2223  fast moving phone virus appear security firm w...           tech   \n",
       "2224  hacker threat apple itunes user apple music ju...           tech   \n",
       "\n",
       "                                  title  \\\n",
       "0       Musicians to tackle US red tape   \n",
       "1          U2's desire to be number one   \n",
       "2      Rocker Doherty in on-stage fight   \n",
       "3      Snicket tops US box office chart   \n",
       "4       Ocean's Twelve raids box office   \n",
       "...                                 ...   \n",
       "2220    Warning over Windows Word files   \n",
       "2221  Fast lifts rise into record books   \n",
       "2222  Nintendo adds media playing to DS   \n",
       "2223   Fast moving phone viruses appear   \n",
       "2224    Hacker threat to Apple's iTunes   \n",
       "\n",
       "                                               contents  \n",
       "0     Musicians' groups are to tackle US visa regula...  \n",
       "1     U2, who have won three prestigious Grammy Awar...  \n",
       "2     Rock singer Pete Doherty has been involved in ...  \n",
       "3     The film adaptation of Lemony Snicket novels h...  \n",
       "4     Ocean's Twelve, the crime caper sequel starrin...  \n",
       "...                                                 ...  \n",
       "2220  Writing a Microsoft Word document can be a dan...  \n",
       "2221  Two high-speed lifts at the world's tallest bu...  \n",
       "2222  Nintendo is releasing an adapter for its DS ha...  \n",
       "2223  Security firms are warning about several mobil...  \n",
       "2224  Users of Apple's music jukebox iTunes need to ...  \n",
       "\n",
       "[2225 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>all</th>\n      <th>theme</th>\n      <th>title</th>\n      <th>contents</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>musician tackle *USA red tape musician group t...</td>\n      <td>entertainment</td>\n      <td>Musicians to tackle US red tape</td>\n      <td>Musicians' groups are to tackle US visa regula...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>u2 desire number one u2 three prestigious gram...</td>\n      <td>entertainment</td>\n      <td>U2's desire to be number one</td>\n      <td>U2, who have won three prestigious Grammy Awar...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>rocker doherty onstage fight rock singer pete ...</td>\n      <td>entertainment</td>\n      <td>Rocker Doherty in on-stage fight</td>\n      <td>Rock singer Pete Doherty has been involved in ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>snicket top *USA box office chart film adaptat...</td>\n      <td>entertainment</td>\n      <td>Snicket tops US box office chart</td>\n      <td>The film adaptation of Lemony Snicket novels h...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ocean twelve raid box office ocean twelve crim...</td>\n      <td>entertainment</td>\n      <td>Ocean's Twelve raids box office</td>\n      <td>Ocean's Twelve, the crime caper sequel starrin...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2220</th>\n      <td>warning window word file writing microsoft wor...</td>\n      <td>tech</td>\n      <td>Warning over Windows Word files</td>\n      <td>Writing a Microsoft Word document can be a dan...</td>\n    </tr>\n    <tr>\n      <th>2221</th>\n      <td>fast lift rise record book two highspeed lift ...</td>\n      <td>tech</td>\n      <td>Fast lifts rise into record books</td>\n      <td>Two high-speed lifts at the world's tallest bu...</td>\n    </tr>\n    <tr>\n      <th>2222</th>\n      <td>nintendo add medium playing d nintendo releasi...</td>\n      <td>tech</td>\n      <td>Nintendo adds media playing to DS</td>\n      <td>Nintendo is releasing an adapter for its DS ha...</td>\n    </tr>\n    <tr>\n      <th>2223</th>\n      <td>fast moving phone virus appear security firm w...</td>\n      <td>tech</td>\n      <td>Fast moving phone viruses appear</td>\n      <td>Security firms are warning about several mobil...</td>\n    </tr>\n    <tr>\n      <th>2224</th>\n      <td>hacker threat apple itunes user apple music ju...</td>\n      <td>tech</td>\n      <td>Hacker threat to Apple's iTunes</td>\n      <td>Users of Apple's music jukebox iTunes need to ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2225 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in g20:\n",
    "    data[each] = [1 if \"*\"+each.upper() in row['all'].split(\" \") else 0 for index, row in data.iterrows()] \n",
    "\n",
    "data['republic of korea'] = (data['republic of korea']+data['korea']).apply(lambda x: 1 if x>=1 else 0)\n",
    "data['saudi arabia'] = (data['saudi arabia']+data['arabia']).apply(lambda x: 1 if x>=1 else 0)\n",
    "data['south africa'] = (data['south africa']+data['africa']).apply(lambda x: 1 if x>=1 else 0)\n",
    "data['united kingdom'] = (data['united kingdom']+data['uk']).apply(lambda x: 1 if x>=1 else 0)\n",
    "data['united states'] = (data['united states']+data['usa'] + data['america']).apply(lambda x: 1 if x>=1 else 0)\n",
    "data['european union'] = (data['european union']+data['eu'] + data['europe']).apply(lambda x: 1 if x>=1 else 0)\n",
    "\n",
    "data.drop(columns=['korea', 'arabia', 'africa', 'uk', 'america' , 'usa', 'eu', 'europe'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('/Users/aditya/Documents/GitHub/tegger-challenge/data.csv')"
   ]
  }
 ]
}